{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "import gym\n",
    "from collections import deque\n",
    "\n",
    "from ignite.engine import Engine, Events\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dqn_agent import Agent\n",
    "\n",
    "seed = 0\n",
    "timesteps = list(range(10000))\n",
    "\n",
    "env = gym.make('LunarLander-v2')\n",
    "env.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "agent = Agent(state_size=8, action_size=4, seed=0)\n",
    "\n",
    "gamma = 0.99\n",
    "eps_start = 1.\n",
    "eps_end = 0.01\n",
    "eps_decay = 0.995\n",
    "\n",
    "now = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "writer = SummaryWriter(\"logs/ddqn/{}\".format(now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODE_STARTED = Events.EPOCH_STARTED\n",
    "EPISODE_COMPLETED = Events.EPOCH_COMPLETED\n",
    "\n",
    "def run_single_timestep(engine, timestep):\n",
    "    eps = engine.state.eps\n",
    "    state = engine.state.current_state\n",
    "    action = agent.act(state, eps)\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    agent.step(state, action, reward, next_state, done)\n",
    "    \n",
    "    engine.state.current_state = next_state\n",
    "    engine.state.score += reward\n",
    "    \n",
    "    if done:\n",
    "        engine.terminate_epoch()\n",
    "        engine.state.timestep = timestep\n",
    "\n",
    "trainer = Engine(run_single_timestep)\n",
    "\n",
    "@trainer.on(Events.STARTED)\n",
    "def initialize(engine):\n",
    "    # lists containing scores from each episode\n",
    "    engine.state.scores = []                        \n",
    "    engine.state.scores_window = deque(maxlen=100)\n",
    "    engine.state.eps = eps_start\n",
    "\n",
    "\n",
    "@trainer.on(EPISODE_STARTED)\n",
    "def reset_environment_state(engine):\n",
    "    engine.state.current_state = env.reset()\n",
    "    engine.state.score = 0\n",
    "\n",
    "@trainer.on(EPISODE_COMPLETED)\n",
    "def update_model(engine):\n",
    "    engine.state.eps = max(eps_end, eps_decay*engine.state.eps) # decrease epsilon\n",
    "    \n",
    "    score = engine.state.score\n",
    "    engine.state.scores.append(score)\n",
    "    engine.state.scores_window.append(score)\n",
    "    \n",
    "@trainer.on(EPISODE_COMPLETED(every=10))\n",
    "def log_episode_to_tensorboard(engine):\n",
    "    i = engine.state.epoch\n",
    "#     writer.add_scalar('running reward', engine.state.running_reward, i_episode)\n",
    "    writer.add_scalar('Average episode score', np.mean(engine.state.scores_window), i)\n",
    "    writer.add_scalar('Average environment score', np.mean(engine.state.scores), i)\n",
    "\n",
    "@trainer.on(EPISODE_COMPLETED)\n",
    "def should_finish_training(engine):\n",
    "    if np.mean(engine.state.scores_window)>=200.0:\n",
    "        print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(engine.state.epoch, np.mean(engine.state.scores_window)))\n",
    "        torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "        engine.should_terminate = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Environment solved in 663 episodes!\tAverage Score: 200.32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "State:\n",
       "\titeration: 377906\n",
       "\tepoch: 663\n",
       "\tepoch_length: 10000\n",
       "\tmax_epochs: 10000\n",
       "\toutput: <class 'NoneType'>\n",
       "\tbatch: 371\n",
       "\tmetrics: <class 'dict'>\n",
       "\tdataloader: <class 'list'>\n",
       "\tseed: <class 'NoneType'>\n",
       "\ttimes: <class 'dict'>\n",
       "\tscores: <class 'list'>\n",
       "\tscores_window: <class 'collections.deque'>\n",
       "\teps: 0.036033175291307735\n",
       "\tcurrent_state: <class 'numpy.ndarray'>\n",
       "\tscore: 242.1907799722907\n",
       "\ttimestep: 371"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.run(timesteps, max_epochs=10000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Unity",
   "language": "python",
   "name": "unity"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
